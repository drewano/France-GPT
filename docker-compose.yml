# Définition des services qui composent l'application
services:

  # --- Service 1: Le serveur MCP ---
  # Ce service exécute le serveur FastMCP qui transforme l'API data.inclusion en outils.
  mcp_server:
    image: france-gpt-mcp-server  # <--- AJOUT : Nom explicite pour l'image
    container_name: france-gpt-mcp-server
    build:
      context: .
      dockerfile: Dockerfile
    # Surcharge la commande par défaut du Dockerfile pour lancer spécifiquement le serveur MCP
    command: python -m src.mcp_server.server
    env_file:
      - .env
    environment:
      # S'assure que le serveur écoute sur le bon port à l'intérieur du conteneur
      - MCP_PORT=8001
    networks:
      - france-gpt-net
    ports:
      - "8001:8001"  # Port for DataInclusion
      - "8002:8002"  # Port for Legifrance
      - "8003:8003"  # Port for La Bonne Alternance
    restart: unless-stopped
    healthcheck:
      # Checks that the MCP server is up and responding
      test: ["CMD-SHELL", "curl -f http://localhost:8001/health && curl -f http://localhost:8002/health && curl -f http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 20s

  # --- Service 2: L'Agent IA et l'interface Chainlit/FastAPI ---
  # C'est le service principal, qui fournit l'interface utilisateur et l'API de chat.
  agent:
    image: france-gpt-agent-ui # <--- AJOUT : Nom explicite pour l'image
    container_name: france-gpt-agent-ui
    build:
      context: .
      dockerfile: Dockerfile
    # La commande par défaut du Dockerfile ("python main.py") est déjà correcte pour ce service
    env_file:
      - .env
    environment:
      # Port sur lequel l'interface Chainlit et l'API de l'agent seront accessibles
      - AGENT_PORT=8000
      # URL pour que l'agent puisse trouver le serveur MCP. 'mcp_server' est le nom du service.
      - MCP_SERVER_HOST_URL=http://mcp_server
      # URL de connexion à la base de données PostgreSQL
      - DATABASE_URL=postgresql+asyncpg://user:password@postgres:5432/france-gpt
      # Mode de fonctionnement pour la journalisation et les configurations
      - ENVIRONMENT=production
      # Secret JWT pour l'authentification Chainlit (requis quand l'authentification est activée)
      - CHAINLIT_AUTH_SECRET=${CHAINLIT_AUTH_SECRET}
      # Configuration AWS pour Localstack S3
      - AWS_ACCESS_KEY_ID=${APP_AWS_ACCESS_KEY}
      - AWS_SECRET_ACCESS_KEY=${APP_AWS_SECRET_KEY}
      - AWS_DEFAULT_REGION=${APP_AWS_REGION}
      - AWS_ENDPOINT_URL=${DEV_AWS_ENDPOINT}
    networks:
      - france-gpt-net
    ports:
      # Expose le port 8000  pour accéder à l'interface Chainlit via http://localhost:8000
      - "8000:8000"
    # S'assure que le serveur MCP et la base de données sont démarrés et sains avant de lancer l'agent
    depends_on:
      mcp_server:
        condition: service_healthy
      postgres:
        condition: service_healthy
      localstack:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      # Vérifie que l'interface Chainlit/FastAPI est bien démarrée
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ... (le reste du fichier reste inchangé) ...
  postgres:
    image: postgres:15-alpine
    container_name: france-gpt-postgres-db
    environment:
      # Configuration de la base de données PostgreSQL pour le développement
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=france-gpt
    volumes:
      # Persistance des données de la base de données sur un volume Docker
      - postgres_data:/var/lib/postgresql/data
    networks:
      - france-gpt-net
    ports:
      # Expose le port PostgreSQL pour connexion locale si nécessaire
      - "5432:5432"
    restart: unless-stopped
    healthcheck:
      # Vérifie que PostgreSQL est prêt à accepter des connexions
      test: ["CMD-SHELL", "pg_isready -U user -d france-gpt"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  # --- Service 4: Localstack (simulation S3) ---
  # Ce service simule les services AWS S3 localement pour le développement et les tests.
  localstack:
    image: localstack/localstack:latest
    container_name: france-gpt-localstack
    ports:
      - "4566:4566"
    environment:
      - SERVICES=s3
      - AWS_DEFAULT_REGION=eu-central-1 # Optionnel: Définir la région par défaut si nécessaire
    volumes:
      - ./localstack-script.sh:/etc/localstack/init/ready.d/script.sh
      - "/var/run/docker.sock:/var/run/docker.sock"
    networks:
      - france-gpt-net
    healthcheck:
      test: ["CMD", "awslocal", "s3", "ls"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped

# Définition des volumes persistants
volumes:
  postgres_data:
    driver: local

# Définition du réseau partagé pour permettre la communication entre les conteneurs
networks:
  france-gpt-net:
    driver: bridge