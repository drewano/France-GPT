# Agent IA pour l'Inclusion Sociale

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python Version](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/release/python-3120/)
[![Frameworks](https://img.shields.io/badge/frameworks-FastAPI%20%7C%20Gradio%20%7C%20FastMCP-orange)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg?logo=docker)](https://www.docker.com/)

Cet agent conversationnel intelligent est con√ßu pour aider les utilisateurs √† naviguer dans l'√©cosyst√®me de l'inclusion sociale en France. Il se connecte √† l'API [data.inclusion.beta.gouv.fr](https://data.inclusion.beta.gouv.fr/) pour fournir des informations pr√©cises et √† jour sur les structures d'aide, les services disponibles et les ressources sur tout le territoire.

L'interface de chat offre une exp√©rience utilisateur transparente, montrant en temps r√©el les outils que l'agent utilise pour trouver des r√©ponses, ce qui permet de comprendre son "raisonnement".

### Aper√ßu de l'interface

*(Image d'exemple montrant le chat, les questions sugg√©r√©es et la visualisation d'un appel d'outil)*

## ‚ú® Fonctionnalit√©s Principales

* **ü§ñ Agent Expert :** Un assistant bas√© sur un LLM (GPT-4) sp√©cialis√© dans les questions d'inclusion sociale.
* **üîå Conversion d'API en Outils :** Utilise **FastMCP** pour transformer dynamiquement la sp√©cification OpenAPI de `data.inclusion` en outils utilisables par l'agent IA.
* **üîç Transparence Totale :** L'interface **Gradio** affiche en temps r√©el les appels aux outils (`search_services`, `get_structure_details`, etc.), permettant de voir exactement comment l'agent obtient ses informations.
* **üí¨ Interface de Chat Moderne :** Une interface utilisateur r√©active et conviviale construite avec Gradio 4.
* **üöÄ Architecture Robuste :** D√©ploiement via **Docker Compose** avec deux services d√©coupl√©s :
    1. Un serveur MCP d√©di√© √† la gestion des outils.
    2. Un serveur pour l'agent IA et l'interface utilisateur.
* **‚öôÔ∏è Configuration Centralis√©e :** Gestion simple des configurations via un fichier `.env` et Pydantic Settings.
* **‚úÖ Pr√™t pour la Production :** Inclut des health-checks, une journalisation structur√©e et une configuration pour le d√©ploiement.
* **üìñ API Document√©e :** L'agent expose sa propre API FastAPI avec une documentation Swagger UI (`/docs`).

## üèóÔ∏è Architecture

Le projet est divis√© en deux services Docker communiquant entre eux, assurant une s√©paration claire des responsabilit√©s et une meilleure modularit√©.

1. **`mcp_server` (Serveur d'Outils)** :
    * Charge la sp√©cification OpenAPI de `data.inclusion`.
    * La transforme en "outils" (fonctions) MCP (Model-Controlled Proxy).
    * Expose ces outils sur un port interne (`8000`) pour que l'agent puisse les consommer.
    * G√®re l'authentification avec l'API `data.inclusion`.

2. **`agent` (Agent & Interface Utilisateur)** :
    * Contient l'agent IA (`pydantic-ai`) qui utilise le mod√®le GPT.
    * Se connecte au `mcp_server` pour d√©couvrir et utiliser les outils disponibles.
    * Expose une interface de chat Gradio sur le port `8001`.
    * Fournit une API FastAPI pour une int√©gration programmatique.

```mermaid
graph TD
    subgraph "Utilisateur"
        User[üë§ Utilisateur] --> Browser[üåê Navigateur Web]
    end

    subgraph "Services Externes"
        DataInclusionAPI["API data.inclusion.beta.gouv.fr"]
        OpenAI_API["API OpenAI (GPT-4)"]
    end

    subgraph "Environnement Docker (datainclusion-net)"
        Browser -- "HTTP/S sur Port 8001" --> AgentService
        
        AgentService -- "1. Requ√™te de l'agent (Pydantic-AI)" --> OpenAI_API
        AgentService -- "3. Appel d'outil (MCP)" --> MCPServer

        MCPServer -- "4. Appel API REST" --> DataInclusionAPI
        MCPServer -- "2. Charge la spec OpenAPI au d√©marrage" --> DataInclusionAPI

        subgraph "Service 'agent' (Port 8001)"
            AgentService["Agent & UI Service
            Interface Gradio
            API FastAPI (/api)
            Agent Pydantic-AI
            main.py"]
        end
        
        subgraph "Service 'mcp_server' (Port 8000)"
            MCPServer["MCP Tool Server 
            FastMCP
            Transforme OpenAPI en outils
            G√®re l'authentification API
            src/mcp_server/server.py"]
        end
    end

    style User fill:#cde4ff,stroke:#333
    style AgentService fill:#d5f5e3,stroke:#27ae60
    style MCPServer fill:#fdebd0,stroke:#f39c12
    style DataInclusionAPI fill:#e8daef,stroke:#8e44ad
    style OpenAI_API fill:#d6eaf8,stroke:#3498db
```

## üõ†Ô∏è Technologies Utilis√©es

* **Backend & IA :** Python 3.12, FastAPI, Pydantic-AI, FastMCP
* **Frontend :** Gradio
* **D√©ploiement :** Docker, Docker Compose
* **D√©pendances :** Uvicorn, HTTPX, python-dotenv

## üöÄ D√©marrage Rapide

### Pr√©requis

* [Docker](https://www.docker.com/get-started)
* [Docker Compose](https://docs.docker.com/compose/install/) (g√©n√©ralement inclus avec Docker Desktop)

### Installation

1. **Clonez le d√©p√¥t :**

    ```bash
    git clone https://github.com/votre-user/datainclusion-mcp-server.git
    cd datainclusion-mcp-server
    ```

2. **Configurez les variables d'environnement :**
    Copiez le fichier d'exemple et modifiez-le pour y ajouter vos cl√©s d'API.

    ```bash
    cp .env.example .env
    ```

    Ouvrez le fichier `.env` et remplissez les valeurs suivantes :

    ```ini
    # Cl√© API pour l'API data.inclusion (obligatoire)
    # Contactez l'√©quipe data.inclusion pour en obtenir une.
    DATA_INCLUSION_API_KEY=VOTRE_CLE_ICI

    # Cl√© API pour le mod√®le de langage (obligatoire)
    # Le projet est configur√© pour OpenAI par d√©faut.
    OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

    # (Optionnel) Cl√© pour s√©curiser le serveur MCP.
    # Si non d√©finie, le serveur MCP sera accessible sans authentification sur le r√©seau Docker.
    MCP_SERVER_SECRET_KEY=une-cle-secrete-aleatoire
    ```

### Initialisation de la base de donn√©es

Cette √©tape est n√©cessaire **une seule fois** apr√®s le premier lancement pour cr√©er les tables de la base de donn√©es PostgreSQL requises par Chainlit.

1. **Lancez tous les services en arri√®re-plan :**
    ```bash
    # 1. Lancez tous les services en arri√®re-plan
    docker-compose up -d --build
    ```

2. **Cr√©ez les tables de la base de donn√©es :**
    ```bash
    # 2. Une fois les conteneurs d√©marr√©s, ex√©cutez la commande de cr√©ation de la base de donn√©es
    docker-compose exec agent chainlit create-db -y
    ```

3. **V√©rifiez le bon fonctionnement :**
    ```bash
    # 3. Vous pouvez maintenant consulter les logs pour v√©rifier que tout fonctionne
    docker-compose logs -f
    ```

4. **Pour les lancements suivants :**
    Une fois l'initialisation termin√©e, vous pouvez utiliser la commande standard :

    ```bash
    docker-compose up --build
    ```

### Acc√®s √† l'application

* **Interface de Chat :** Ouvrez votre navigateur et allez √† [**http://localhost:8001/chat**](http://localhost:8001/chat)
* **API de l'agent :** La documentation est disponible sur [http://localhost:8001/docs](http://localhost:8001/docs)
* **Health Check :** [http://localhost:8001/health](http://localhost:8001/health)

## üîß Configuration (Variables d'environnement)

Toutes les configurations sont g√©r√©es via le fichier `.env`.

| Variable                               | Description                                                                                             | Service Concern√© |
| -------------------------------------- | ------------------------------------------------------------------------------------------------------- | ---------------- |
| `OPENAPI_URL`                          | URL de la sp√©cification OpenAPI √† utiliser pour g√©n√©rer les outils.                                     | `mcp_server`     |
| `DATA_INCLUSION_API_KEY`               | **(Requis)** Cl√© API pour s'authentifier aupr√®s de l'API `data.inclusion`.                                  | `mcp_server`     |
| `MCP_SERVER_SECRET_KEY`                | Cl√© secr√®te pour signer les tokens d'acc√®s au serveur MCP. Si vide, l'authentification est d√©sactiv√©e. | `mcp_server`     |
| `OPENAI_API_KEY`                       | **(Requis)** Votre cl√© API OpenAI pour le mod√®le de langage.                                              | `agent`          |
| `AGENT_MODEL_NAME`                     | Nom du mod√®le OpenAI √† utiliser (ex: `gpt-4.1`, `gpt-4-turbo`).                                           | `agent`          |
| `AGENT_PORT`                           | Port sur lequel l'interface Gradio et l'API de l'agent seront expos√©es.                                   | `agent`          |
| `MCP_SERVER_URL`                       | URL interne pour que l'agent se connecte au serveur MCP. Ne pas modifier si vous utilisez Docker.       | `agent`          |
| `ENVIRONMENT`                          | Mode de l'application (`production` ou `development`).                                                  | `agent`          |

## üßë‚Äçüíª D√©veloppement Local (Sans Docker)

Si vous souhaitez ex√©cuter les services localement pour le d√©veloppement :

1. **Installez les d√©pendances :**

    ```bash
    pip install uv  # Installer le gestionnaire de paquets rapide
    uv pip install -r pyproject.toml
    ```

2. **Configurez votre fichier `.env`.**

3. **Lancez le serveur MCP :**
    Dans un premier terminal :

    ```bash
    python -m src.mcp_server.server
    ```

    Il tournera par d√©faut sur `http://localhost:8000`.

4. **Lancez l'agent et l'UI :**
    Dans un second terminal, assurez-vous que `MCP_SERVER_URL` dans votre `.env` pointe vers `http://localhost:8000/mcp` et que `AGENT_PORT` est diff√©rent (ex: `8001`).

    ```bash
    # Pour le mode d√©veloppement avec rechargement automatique
    python main.py
    ```

## üìú Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.
