# FranceGPT ğŸ‡«ğŸ‡·

<div align="center">
<a href="https://www.python.org" target="_blank" rel="noreferrer">
<img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="Python" height="40"/>
</a>
<a href="https://fastapi.tiangolo.com/" target="_blank" rel="noreferrer">
<img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/fastapi/fastapi-original.svg" alt="FastAPI" height="40"/>
</a>
<a href="https://ai.pydantic.dev/" target="_blank" rel="noreferrer">
<img src="https://avatars.githubusercontent.com/u/110818415?v=4" alt="Pydantic-AI" height="40"/>
</a>
<a href="https://chainlit.io/" target="_blank" rel="noreferrer">
<img src="https://avatars.githubusercontent.com/u/128686189?s=200&v=4" alt="Chainlit" height="40"/>
</a>
<a href="https://www.docker.com/" target="_blank" rel="noreferrer">
<img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/docker/docker-original.svg" alt="Docker" height="40"/>
</a>
<a href="https://gofastmcp.com/getting-started/welcome" target="_blank" rel="noreferrer">
<img src="https://img.shields.io/badge/FastMCP-%238A2BE2.svg?style=flat&logo=bolt&logoColor=white" alt="FastMCP" height="40"/>
</a>
</div>
<br/>

FranceGPT est une application conversationnelle de type ChatGPT, conÃ§ue pour interagir avec les donnÃ©es publiques franÃ§aises. Elle hÃ©berge une collection d'**Agents IA spÃ©cialisÃ©s** qui exploitent les API de `data.gouv.fr` (LÃ©gifrance, Data.Inclusion, INSEE, etc.) en les transformant en outils puissants et fiables pour les modÃ¨les de langage (LLM).


*(Image d'illustration : L'interface Chainlit avec la sÃ©lection des profils d'agents spÃ©cialisÃ©s.)*

## ğŸ¯ Le Besoin Fondamental

Les API gouvernementales, bien que riches en informations, ne sont pas directement utilisables par les agents IA. Leurs schÃ©mas complexes et leurs formats de donnÃ©es brutes constituent une barriÃ¨re.

**FranceGPT est nÃ© d'un besoin fondamental :** il faut transformer l'accÃ¨s Ã  ces API en **outils MCP (Model Context Protocol)**. Le protocole MCP standardise la communication entre les LLM et les services externes, rendant les interactions plus fiables, sÃ©curisÃ©es et comprÃ©hensibles pour l'IA.

Ce projet sert de pont, permettant aux agents IA de non seulement consommer les donnÃ©es publiques, mais aussi de les comprendre, de les croiser et de crÃ©er des workflows complexes pour automatiser des tÃ¢ches et fournir des rÃ©ponses prÃ©cises et contextualisÃ©es.

## âœ¨ FonctionnalitÃ©s ClÃ©s

- **ğŸ¤– Collection d'Agents SpÃ©cialisÃ©s** : Des agents prÃ©-configurÃ©s comme l'**Agent Social** (basÃ© sur Data.Inclusion) et l'**Agent Juridique** (basÃ© sur LÃ©gifrance), chacun avec son propre prompt systÃ¨me et ses outils dÃ©diÃ©s.
- **ğŸ”Œ Serveurs MCP Dynamiques** : Utilise **FastMCP** pour crÃ©er dynamiquement des serveurs MCP pour chaque API gouvernementale configurÃ©e, rendant le systÃ¨me extensible Ã  de nouvelles sources de donnÃ©es.
- **ğŸ› ï¸ Transformation d'Outils AvancÃ©e** : Ne se contente pas de convertir les endpoints OpenAPI. Un `ToolTransformer` enrichit les outils gÃ©nÃ©rÃ©s avec des noms plus clairs, des descriptions amÃ©liorÃ©es et des schÃ©mas optimisÃ©s pour une meilleure comprÃ©hension par les LLM.
- **ğŸ’¬ Interface Moderne avec Streaming** : Une interface utilisateur Ã©purÃ©e de type ChatGPT construite avec **Chainlit**, offrant une expÃ©rience de streaming fluide qui montre en temps rÃ©el les appels d'outils (`cl.Step`).
- **ğŸ§  Agents Intelligents avec Pydantic AI** : Utilise **Pydantic AI** pour la crÃ©ation d'agents robustes, la gestion de l'historique des conversations et l'orchestration des appels d'outils.
- **ğŸ“¦ Architecture Modulaire et ConteneurisÃ©e** : Une sÃ©paration claire des services (UI, Serveurs MCP, Base de donnÃ©es) via Docker, assurant la scalabilitÃ© et la facilitÃ© de dÃ©ploiement.
- **ğŸ’¾ Persistance des DonnÃ©es** : Sauvegarde des conversations, des utilisateurs et des Ã©lÃ©ments grÃ¢ce Ã  l'intÃ©gration de la couche de donnÃ©es de Chainlit avec une base de donnÃ©es PostgreSQL.

## ğŸ—ï¸ Architecture du Projet

L'architecture de FranceGPT est conÃ§ue pour Ãªtre modulaire et robuste, sÃ©parant clairement les responsabilitÃ©s de chaque composant.

```mermaid
graph TD
    subgraph "Navigateur Utilisateur"
        UI[ğŸ’» Interface Chainlit]
    end

    subgraph "Service Agent (agent)"
        A[ğŸ¤– Agent Pydantic AI]
        F[ğŸŒ FastAPI]
        DB[(ğŸ˜ PostgreSQL)]
        S3[(ğŸ“¦ S3 / Localstack)]
    end
    
    subgraph "Service MCP (mcp_server)"
        MCP_DI[ğŸš€ Serveur MCP Data.Inclusion]
        MCP_LF[âš–ï¸ Serveur MCP LÃ©gifrance]
        MCP_Autres[...]
    end

    subgraph "API Externes"
        API_DI[API Data.Inclusion]
        API_LF[API LÃ©gifrance]
        API_Autres[...]
    end

    UI -- RequÃªte utilisateur --> F
    F -- Appelle --> A
    A -- Utilise des outils --> MCP_DI
    A -- Utilise des outils --> MCP_LF
    MCP_DI -- Appelle --> API_DI
    MCP_LF -- Appelle --> API_LF
    F -- Persistance --> DB
    F -- Stockage Ã‰lÃ©ments --> S3
```
1.  **Interface Utilisateur (Chainlit)** : L'utilisateur interagit avec l'un des agents spÃ©cialisÃ©s.
2.  **Service Agent (FastAPI + Pydantic AI)** :
    - ReÃ§oit la requÃªte de l'utilisateur.
    - L'**Agent Pydantic AI** sÃ©lectionnÃ© traite la demande.
    - Si nÃ©cessaire, l'agent dÃ©cide d'utiliser un ou plusieurs outils. Il communique avec le service MCP appropriÃ©.
3.  **Service MCP (FastMCP)** :
    - Le serveur MCP reÃ§oit la demande d'appel d'outil.
    - Il traduit cet appel en une requÃªte HTTP standard vers l'API gouvernementale externe (ex: Data.Inclusion).
    - Il reÃ§oit la rÃ©ponse de l'API, la formate et la renvoie Ã  l'agent.
4.  **Agent & UI** : L'agent reÃ§oit le rÃ©sultat de l'outil, formule une rÃ©ponse finale et la streame Ã  l'utilisateur via l'interface Chainlit.

## ğŸ› ï¸ Technologies UtilisÃ©es

| Technologie | RÃ´le |
| :--- | :--- |
| **Pydantic AI** | CrÃ©ation des agents IA, gestion des conversations et orchestration des outils. |
| **FastMCP** | Transformation des API REST en serveurs d'outils standardisÃ©s (MCP). |
| **Chainlit** | Fourniture de l'interface utilisateur conversationnelle "ChatGPT-like". |
| **FastAPI** | Serveur web principal pour hÃ©berger l'application Chainlit. |
| **Docker & Docker Compose**| Conteneurisation et orchestration de tous les services de l'application. |
| **PostgreSQL** | Base de donnÃ©es pour la persistance des conversations et des utilisateurs (via Chainlit). |
| **SQLAlchemy** | ORM pour interagir avec la base de donnÃ©es PostgreSQL. |
| **Localstack** | Simulation locale des services AWS (S3) pour le stockage des Ã©lÃ©ments Chainlit. |

## ğŸš€ Installation et Lancement

Le projet est entiÃ¨rement conteneurisÃ© avec Docker, ce qui simplifie grandement son installation.

### PrÃ©requis

-   [Docker](https://www.docker.com/get-started)
-   [Docker Compose](https://docs.docker.com/compose/install/)

### Ã‰tapes

1.  **Cloner le dÃ©pÃ´t :**
    ```bash
    git clone https://github.com/votre-user/france-gpt.git
    cd france-gpt
    ```

2.  **Configurer les variables d'environnement :**
    Copiez le fichier d'exemple et remplissez les clÃ©s d'API nÃ©cessaires.
    ```bash
    cp .env.example .env
    ```
    Ouvrez le fichier `.env` et ajoutez vos clÃ©s pour :
    - `DATAINCLUSION_API_KEY`
    - `LEGIFRANCE_OAUTH_CLIENT_ID`
    - `LEGIFRANCE_OAUTH_CLIENT_SECRET`
    - `OPENAI_API_KEY` (ou configurez `OPENAI_API_BASE_URL` si vous utilisez un service compatible comme Ollama)

3.  **Lancer l'application avec Docker Compose :**
    Cette commande va construire les images Docker et dÃ©marrer tous les services (serveurs MCP, agent, base de donnÃ©es).
    ```bash
    docker-compose up --build -d
    ```

4.  **AccÃ©der Ã  l'application :**
    -   **Interface FranceGPT (Chainlit)** : [http://localhost:8001](http://localhost:8001)
    -   Serveur MCP Data.Inclusion (pour test) : `http://localhost:8000/health`
    -   Serveur MCP LÃ©gifrance (pour test) : `http://localhost:8002/health`

    > âœ¨ Le premier dÃ©marrage peut prendre quelques minutes le temps de tÃ©lÃ©charger les images de base et d'installer les dÃ©pendances.

## ğŸ“‚ Structure du DÃ©pÃ´t

```
france-gpt/
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .env.example
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ main.py                # Point d'entrÃ©e de l'application FastAPI/Chainlit
â”œâ”€â”€ pyproject.toml         # DÃ©pendances du projet
â””â”€â”€ src/
    â”œâ”€â”€ agent/             # Logique des agents Pydantic AI
    â”‚   â”œâ”€â”€ agent.py       # Factory de crÃ©ation des agents
    â”‚   â””â”€â”€ ui_tools.py    # Outils spÃ©cifiques Ã  l'UI (ex: afficher un site web)
    â”œâ”€â”€ app/               # Configuration de l'application FastAPI
    â”‚   â””â”€â”€ factory.py     # Factory de crÃ©ation de l'app FastAPI
    â”œâ”€â”€ core/              # Configuration centrale, profils, etc.
    â”‚   â”œâ”€â”€ config.py      # Gestion de la configuration (Pydantic Settings)
    â”‚   â”œâ”€â”€ lifespan.py    # Logique de dÃ©marrage/arrÃªt de l'app
    â”‚   â””â”€â”€ profiles.py    # DÃ©finition des profils d'agents (Agent Social, etc.)
    â”œâ”€â”€ db/                # Configuration de la base de donnÃ©es SQLAlchemy
    â”‚   â”œâ”€â”€ models.py      # ModÃ¨les de tables pour Chainlit
    â”‚   â””â”€â”€ session.py     # Initialisation de la base de donnÃ©es
    â”œâ”€â”€ mcp_server/        # Logique des serveurs FastMCP
    â”‚   â”œâ”€â”€ server.py      # Point d'entrÃ©e des serveurs MCP
    â”‚   â”œâ”€â”€ factory.py     # Factory pour construire les serveurs MCP
    â”‚   â”œâ”€â”€ tool_transformer.py # Enrichissement des outils gÃ©nÃ©rÃ©s
    â”‚   â””â”€â”€ services/      # Configurations par service (OpenAPI, mappings...)
    â””â”€â”€ ui/                # Code de l'interface Chainlit
        â”œâ”€â”€ chat.py        # Logique de l'interface (on_message, profils...)
        â”œâ”€â”€ data_layer.py  # Configuration de la persistance Chainlit
        â””â”€â”€ streaming.py   # Gestion avancÃ©e du streaming des rÃ©ponses
```

## ğŸ’¡ Comment Ã§a marche ?

### 1. Le Serveur MCP (`FastMCP`)

Le cÅ“ur de la transformation API-vers-outil. Le `mcp_server/server.py` lit la variable `MCP_SERVICES_CONFIG` du fichier `.env`. Pour chaque service dÃ©fini (comme `datainclusion` ou `legifrance`), il utilise `MCPFactory` pour :
1.  Charger le fichier `openapi.json` du service.
2.  CrÃ©er un client HTTP authentifiÃ© (Bearer ou OAuth2).
3.  Initialiser un serveur `FastMCP` qui gÃ©nÃ¨re automatiquement des outils Ã  partir des endpoints OpenAPI.
4.  Appliquer le **`ToolTransformer`** : cette Ã©tape cruciale utilise le fichier `mappings.json` pour renommer les outils (ex: `list_structures_..._get` devient `list_all_structures`), enrichir leurs descriptions et leurs paramÃ¨tres pour les rendre plus intuitifs pour un LLM.

### 2. L'Agent IA (`Pydantic AI`)

Quand un utilisateur interagit, `ui/chat.py` sÃ©lectionne un profil d'agent dÃ©fini dans `core/profiles.py`. La factory `agent/agent.py` crÃ©e alors une instance de `pydantic_ai.Agent` :
-   Le **modÃ¨le LLM** est configurÃ© (ex: `gpt-4.1-mini`).
-   Le **prompt systÃ¨me** du profil est injectÃ© pour donner Ã  l'agent son rÃ´le et ses instructions.
-   Le **toolset MCP** est connectÃ© en pointant vers l'URL du serveur MCP correspondant (`http://mcp_server:8000/mcp/`).
-   Des **outils d'interface** (`ui_tools.py`) sont Ã©galement ajoutÃ©s, permettant Ã  l'agent d'agir sur l'UI (ex: afficher un site web dans la barre latÃ©rale).

### 3. L'Interface Utilisateur (`Chainlit`)

`Chainlit` gÃ¨re tout le front-end.
-   **`@cl.set_chat_profiles`** affiche les diffÃ©rents agents disponibles au dÃ©marrage.
-   **`@cl.on_message`** intercepte le message de l'utilisateur.
-   La fonction `process_agent_modern_with_history` est appelÃ©e. Elle utilise la mÃ©thode `agent.iter()` de Pydantic AI, qui est la maniÃ¨re la plus moderne et robuste de gÃ©rer une conversation.
-   Elle parcourt le graphe d'exÃ©cution de l'agent nÅ“ud par nÅ“ud (`ModelRequestNode`, `CallToolsNode`, etc.), ce qui permet d'afficher en temps rÃ©el les appels d'outils dans des `cl.Step` et de streamer la rÃ©ponse finale token par token.

## ğŸ¤ Contribuer

Les contributions sont les bienvenues ! Que ce soit pour ajouter de nouveaux agents, intÃ©grer de nouvelles API `data.gouv`, amÃ©liorer la documentation ou corriger des bugs, n'hÃ©sitez pas Ã  ouvrir une Pull Request ou une Issue.

## ğŸ“œ Licence

Ce projet est distribuÃ© sous la licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.
