---

# Agent IA pour l'API Data Inclusion

[![Python Version](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/release/python-3120/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)](https://fastapi.tiangolo.com/)
[![Chainlit](https://img.shields.io/badge/Chainlit-4B5563?style=for-the-badge)](https://chainlit.io/)

Ce projet fournit un agent conversationnel intelligent con√ßu pour interagir avec l'API [data.inclusion.beta.gouv.fr](https://data.inclusion.beta.gouv.fr/). Gr√¢ce √† une interface de chat moderne, il permet aux utilisateurs (travailleurs sociaux, citoyens, etc.) de poser des questions en langage naturel pour trouver des structures et services d'aide sociale en France.

L'agent est capable de comprendre des requ√™tes complexes, d'utiliser les outils d'API appropri√©s et de fournir des r√©ponses pr√©cises et contextualis√©es en temps r√©el.

## ‚ú® Fonctionnalit√©s Cl√©s

- **Interface de Chat Intuitive** : Une interface utilisateur propre et r√©active construite avec [Chainlit](https://chainlit.io/) pour une exp√©rience conversationnelle fluide.
- **Requ√™tes en Langage Naturel** : Posez des questions comme "Trouve-moi des services d'aide alimentaire pr√®s de Lyon" ou "Quelles structures proposent un accompagnement num√©rique pour les seniors ?".
- **G√©n√©ration d'Outils Automatis√©e** : Le serveur [FastMCP](https://github.com/mcp-ai/fastmcp) transforme dynamiquement la sp√©cification OpenAPI de Data Inclusion en outils utilisables par le LLM.
- **R√©ponses en Streaming** : Les r√©ponses de l'agent s'affichent en temps r√©el, token par token, pour une meilleure interactivit√©.
- **Historique de Conversation** : Les conversations sont sauvegard√©es dans une base de donn√©es PostgreSQL, permettant aux utilisateurs de reprendre leurs sessions.
- **Architecture Robuste et Modulaire** : Enti√®rement conteneuris√© avec Docker et Docker Compose, s√©parant l'agent, le serveur d'outils (MCP) et la base de donn√©es.
- **Authentification S√©curis√©e** : Support de l'authentification par mot de passe pour l'interface de chat et par jeton Bearer pour le serveur MCP.

## üèõÔ∏è Architecture

Le projet est compos√© de trois services principaux orchestr√©s par Docker Compose :

1.  **Agent & UI (Service `agent`)** : Une application FastAPI qui h√©berge l'interface de chat Chainlit. Elle contient la logique de l'agent (bas√©e sur `pydantic-ai`) qui re√ßoit les prompts de l'utilisateur, dialogue avec le LLM, et appelle les outils du serveur MCP pour obtenir des donn√©es.
2.  **Serveur d'Outils (Service `mcp_server`)** : Un serveur FastMCP qui lit la sp√©cification `openapi.json` de l'API Data Inclusion, la transforme en un ensemble d'outils (ex: `search_services`, `get_structure_details`) et les expose via le *Model Context Protocol* (MCP). Il agit comme un pont s√©curis√© et structur√© entre l'agent et l'API r√©elle.
3.  **Base de Donn√©es (Service `postgres`)** : Une instance PostgreSQL utilis√©e par Chainlit pour persister les utilisateurs, les conversations et les messages, offrant une exp√©rience utilisateur continue.

Voici un diagramme illustrant le flux des informations :

```mermaid
graph TD
    subgraph "Navigateur de l'Utilisateur"
        A[Interface Chainlit]
    end

    subgraph "Service Agent (FastAPI)"
        B[Logique de l'Agent - Pydantic-AI]
        C[API de Chat - /api/chat]
    end

    subgraph "Service MCP Server"
        D[Serveur d'Outils FastMCP]
    end

    subgraph "Services Externes"
        E[API LLM - ex: OpenAI]
        F[API Data Inclusion]
    end

    subgraph "Base de donn√©es"
        G[PostgreSQL]
    end

    A -- Prompt utilisateur --> B
    B -- Requ√™te format√©e --> E
    E -- Raisonnement et Appel d'outil --> B
    B -- Appel d'outil MCP --> D
    D -- Requ√™te API --> F
    F -- Donn√©es --> D
    D -- R√©sultat de l'outil --> B
    B -- Formate la r√©ponse --> E
    E -- R√©ponse en langage naturel --> B
    B -- R√©ponse en streaming --> A
    A <-->|Historique des chats| G

```

## üöÄ D√©marrage Rapide

Pour lancer le projet, vous aurez besoin de Docker et Docker Compose.

### 1. Pr√©requis

- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)

### 2. Configuration

1.  Clonez ce d√©p√¥t :
    ```bash
    git clone https://github.com/votre-user/datainclusion-mcp-server.git
    cd datainclusion-mcp-server
    ```

2.  Cr√©ez un fichier `.env` √† partir de l'exemple fourni :
    ```bash
    cp .env.example .env
    ```

3.  Modifiez le fichier `.env` pour y ajouter vos cl√©s d'API :
    ```dotenv
    # Cl√© API OpenAI (ou d'un service compatible comme Ollama via OPENAI_API_BASE_URL)
    OPENAI_API_KEY="sk-..."

    # Cl√© API pour data.inclusion.beta.gouv.fr (si vous en avez une)
    DATA_INCLUSION_API_KEY="di_api_..."
    
    # Secret pour l'authentification Chainlit (changez cette valeur)
    CHAINLIT_AUTH_SECRET="votre_secret_aleatoire_tres_long"

    # Les autres valeurs par d√©faut sont configur√©es pour fonctionner avec Docker Compose.
    ```

### 3. Lancement de l'application

Lancez l'ensemble des services avec Docker Compose :

```bash
docker-compose up --build
```

Cette commande va :
- Construire les images Docker pour les services `agent` et `mcp_server`.
- D√©marrer les trois conteneurs (`agent`, `mcp_server`, `postgres`).
- √âtablir un r√©seau commun pour qu'ils puissent communiquer entre eux.

Le d√©marrage peut prendre une minute, le temps que les healthchecks (v√©rifications de sant√©) valident que chaque service est pr√™t.

## üí¨ Utilisation

1.  **Acc√©der √† l'interface de chat** :
    Ouvrez votre navigateur et allez √† l'adresse [**http://localhost:8001**](http://localhost:8001).

2.  **Authentification** :
    Utilisez les identifiants par d√©faut pour vous connecter :
    - **Nom d'utilisateur** : `admin`
    - **Mot de passe** : `admin`

3.  **Discutez avec l'agent** :
    Vous pouvez maintenant poser vos questions. Voici quelques exemples :
    - "Quels sont les diff√©rents types de services disponibles ?"
    - "Trouve-moi des points d'acc√®s au num√©rique √† Bordeaux."
    - "Je cherche une aide alimentaire d'urgence √† Paris 18√®me."
    - "Donne-moi les d√©tails de la structure 'PIMMS M√©diation Lyon M√©tropole'."

### Acc√®s aux services pour les d√©veloppeurs

- **Serveur MCP** : L'endpoint du serveur d'outils est accessible √† [http://localhost:8000/mcp/](http://localhost:8000/mcp/).
- **API de l'agent** : La documentation de l'API FastAPI de l'agent est disponible sur [http://localhost:8001/docs](http://localhost:8001/docs).
- **Base de donn√©es** : Le service PostgreSQL est expos√© sur le port `5432` de votre machine h√¥te.

## üõ†Ô∏è Configuration des Variables d'Environnement

Voici les principales variables que vous pouvez configurer dans votre fichier `.env` :

| Variable                               | Description                                                                                              | Exemple                                                        |
| -------------------------------------- | -------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------- |
| `OPENAI_API_KEY`                       | **Requis.** Votre cl√© d'API pour OpenAI.                                                                 | `sk-...`                                                       |
| `AGENT_MODEL_NAME`                     | Le mod√®le de langage √† utiliser pour l'agent.                                                            | `gpt-4.1`                                                      |
| `DATA_INCLUSION_API_KEY`               | Cl√© d'API pour acc√©der aux endpoints authentifi√©s de Data Inclusion.                                     | `di_api_...`                                                   |
| `DATABASE_URL`                         | URL de connexion √† la base de donn√©es PostgreSQL. La valeur par d√©faut est correcte pour Docker Compose. | `postgresql+asyncpg://user:password@postgres:5432/datainclusion` |
| `CHAINLIT_AUTH_SECRET`                 | Cl√© secr√®te pour signer les jetons d'authentification de Chainlit. **√Ä changer pour la production.**      | `un_secret_complexe_et_aleatoire`                              |
| `AGENT_PORT`                           | Port sur lequel l'interface de chat et l'API de l'agent sont expos√©es.                                   | `8001`                                                         |
| `MCP_PORT`                             | Port sur lequel le serveur d'outils MCP est expos√©.                                                      | `8000`                                                         |
| `MCP_SERVER_SECRET_KEY`                | Cl√© secr√®te pour s√©curiser le serveur MCP avec des jetons Bearer. Si vide, l'authentification est d√©sactiv√©e. | `un_autre_secret_complexe`                                     |
| `OPENAI_API_BASE_URL`                  | Optionnel. URL pour utiliser une API compatible OpenAI (ex: Ollama, vLLM).                                 | `http://host.docker.internal:11434/v1`                         |

## ‚öñÔ∏è Licence

Ce projet est distribu√© sous la licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.